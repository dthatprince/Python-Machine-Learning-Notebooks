{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Nigeria: Introductory Machine Learning\n",
    "\n",
    "![](../Images/banner.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRODUCTION TO CLASSIFICATION\n",
    "\n",
    "## Course Overview \n",
    "\n",
    "Upon completion of this study unit, you should be able to:\n",
    "\n",
    "- Distingish the different types classification based on class\n",
    "\n",
    "- List types of classification algorithms \n",
    "\n",
    "- Build a classification algorithms using SKLearn\n",
    "\n",
    "- Evaluation a classification models performance \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Classification, we predict the category a data belongs to ie. Classification algorithms are used to predict labels\n",
    "* Spam Detection\n",
    "* Churn Prediction\n",
    "* Sentiment Analysis\n",
    "* Dog Breed Detection\n",
    "\n",
    "### TYPES OF CLASSIFICATION TASK\n",
    "\n",
    "* Binary classification eg. e-mail spam detection (1 ->spam; or 0→not spam), biometric identification, whether a customer will default or Not\n",
    "* Multi-class classification eg. digit recognition (where classes go from 0 to 9), predicting a party that wins the election,  \n",
    "\n",
    "<center><img src=\"..\\Images\\class.png\" style=\"width: 800px; height:400px\"/></center>\n",
    "\n",
    "\n",
    "### Types of Classification Algorithms\n",
    "- Logistic Regression         \n",
    "- Naive Bayes Classifier\n",
    "- Nearest Neighbor\t\t\t\n",
    "- Support Vector Machines\n",
    "- Decision Trees\t\t\t\t\n",
    "- Boosted Trees\n",
    "- Random Forest\t            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Scikit-learn\n",
    "\n",
    "Scikit-learn is a library in Python that provides many supervised learning and unsupervised algorithms. It’s built upon some of the packages you already familiar with, like NumPy, Pandas, and Matplotlib!\n",
    "\n",
    "The functionality that scikit-learn provides include:\n",
    "\n",
    "- Regression\n",
    "\n",
    "- Classification\n",
    "\n",
    "- Clustering\n",
    "\n",
    "- Model selection\n",
    "\n",
    "- Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "The easiest way to install scikit-learn is using:\n",
    "\n",
    "`pip install -U scikit-learn`\n",
    "\n",
    "or \n",
    "\n",
    "`conda install -c conda-forge scikit-learn`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Scikit-learn Module\n",
    "\n",
    "\n",
    "Some of the classsification models that can be imported from sklearn library includes:\n",
    "\n",
    "* **Logistic Regression**: `from sklearn.linear_model import LogisticRegression`\n",
    "* **K Nearest Neighbor**: `from sklearn.neighbors import KNeighborsClassifier`\n",
    "* **Support Vector Machine**: `from sklearn.svm import SVC`\n",
    "* **Decision Trees Classifier**: `from sklearn.tree import DecisionTreeClassifier`\n",
    "* **Random Forest Classifier**: `from sklearn.ensemble import RandomForestClassifier`\n",
    "* **Gradient Boost Classifier**: `from sklearn.ensemble import GradientBoostingClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Classification Machine Learning Model for AXA Mansard Medical Insurance \n",
    "\n",
    "### Problem statement\n",
    "\n",
    "You work as an analyst in the marketing department of a company that provides various medical insurance in Nigeria. Your manager is unhappy with the low sales volume of a specific kind of insurance. The data engeenier provides you with a sample dataset for those that visit the company webiste for medical insurance.\n",
    "\n",
    "The dataset contains the following columns:\n",
    "\n",
    "- User ID\n",
    "- Gender\n",
    "- Age\n",
    "- Salary\n",
    "- Purchase: An indicator of wheather the users purchased (1) or not-purchased (0) a particular product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plan to use the following classifier to predict whether a person that visit the insurance company will buy or not.\n",
    "\n",
    "- Logist regression\n",
    "\n",
    "- Random forest\n",
    "\n",
    "- Naive Bayes\n",
    "\n",
    "- XGBoost\n",
    "\n",
    "- Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Python modules\n",
    "\n",
    "We need to import some packages that will enable us to explore the data and build machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance = pd.read_csv(\"../Data/Medical_insurance_dataset.csv\")\n",
    "\n",
    "insurance.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 5 variables and 400 instances of those that want to buy medical insurance or not in this data. The User ID is a random number generated for every customer to comes to the company for medical insurance. Therefore, it is not useful in prediciting whether the person will buy medical insurance or not. We will therefore, remove that variable from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.drop([\"User ID\"], axis= \"columns\", inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to transform or recode the label Purchased to have $1$ for those that bought the insurance and $0$ for those that did not purchased the insurance. This will transform the output variable (label) to be numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance[\"Purchased\"] = insurance[\"Purchased\"].apply(lambda x: 1 if x == \"purchased\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 3 features that include `gender`, `age`, and `estimated salary` while `purchased` is the label in this data. Since the label has just two classes or categories (purchased (1) and not-purchased (0)), this is a binary classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "Fact generated by data exploratory will help us to know those features that can predict whether a person will purhcase medical insurance or not. Let us start by visualizing the proportion of those that want to buy medical insurance or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = \"Purchased\", data = insurance);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, majority of those that visit the medical insurance company did not want to buy the insurance. This is an example of class imbalanced. That is, there is no equal of proportion of those that will buy or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = \"Gender\", data = insurance);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proportion of males are almost the same as females."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = \"Gender\" , hue = \"Purchased\", data = insurance);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that females wanted to purchase the insurance when compare with males."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = \"Purchased\", y = \"Age\", data = insurance);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the look of things, other people purchased the insurance compared with the younger people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = \"Purchased\", y = \"EstimatedSalary\", data = insurance);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People that earned higher salary purchased the insurance while those that earned low did not purchase the insurance. Of course, it is expected you purchase a medical insurance when you have money."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importing machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing \n",
    "- Separating features and the label from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now is the time to build machine learning models for the task of predicting whether the customers will buy medical insurance or not. Therefore, we shall separate the set of features (X) from the label (Y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into features and target\n",
    "\n",
    "X = insurance.drop([\"Purchased\"], axis= \"columns\") # droping the label variable (Purchased) from the data\n",
    "\n",
    "y = insurance[\"Purchased\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As dicussed in Part 3, we need to create a one-hot encoding for all the categorical features in the data because some algorithms cannot work with categorical data directly. They require all input variables and output variables to be numeric. In this case, we will create a one-hot encoding for the gender feature by using `pd.get_dummies()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(insurance[\"Gender\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, `pd.get_dummies()` is very powerful to actually locate the categorical features and create a one-hot encoding for them. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now save this result of one-hot encoding into X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split the data into training and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in A, We will split our dataset (Features (X) and Label (Y)) into training and test data by using `train_test_split()` function from the sklearn. The training set will be $80\\%$ while the test set will be $20\\%$. The `random_state` that is set to 1234 is for all of us to have the same set of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state= 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the pair of training data `(X_train, y_train)` and test data `(X_test, y_test)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model training\n",
    "\n",
    "We will use the training data to build the model and then use test data to make prediction and evaluation respectively.\n",
    "\n",
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a Logistic regression model with our training data. We need to import the Logistic regression from the sklearn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create an object of class `LogisticRegression()` to train the model on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticmodel = LogisticRegression()\n",
    "\n",
    "logisticmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`logisticmodel.fit` trained the Logistic regression model. The model is now ready to make prediction for the unknown label by using only the features from the test data (`X_test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the prediction result into `logistic_prediction`. This is what the model predicted for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_prediction = logisticmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we know the true label in the test set (i.e. `y_test`), we can compare this prediction with it, hence evaluate the logistic model. I have created a function that will help you visualize a confusion matrix for the logistic model and you can call on it henceforth to check the performance of any model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConfusionMatrix(ytest, ypred, label = [\"Negative\", \"Positive\"]):\n",
    "    \"A beautiful confusion matrix function to check the model performance\"\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import seaborn as sns\n",
    "    cm = confusion_matrix(ytest, ypred)\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    sns.heatmap(cm, annot = True, cbar = False, fmt = 'd', cmap = 'YlGn')\n",
    "    plt.xlabel('Predicted', fontsize = 13)\n",
    "    plt.xticks([0.5, 1.5], label)\n",
    "    plt.yticks([0.5, 1.5], label)\n",
    "    plt.ylabel('Truth', fontsize = 13)\n",
    "    plt.title('A confusion matrix');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the `ConfusionMatrix()` function, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrix(y_test, logistic_prediction, label= [\"not-purchaed\", \"purchased\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of the Naive model evaluation performance\n",
    "\n",
    "\n",
    "There are 53 True Negatives (TN): predicting that the customer will not buy the insurance and truly the customer did not buy the insurance.\n",
    "\n",
    "There are 27 False Negative (FN): predicting that the customer will not buy the insurance and the customer actually bought the insurance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can check the accuracy by using:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test, logistic_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the model is $66.25\\%$. We cannot trust this accuracy since the data is class imbalanced. Therefore, we are going to use F1 score instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(y_test, logistic_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the confusion matrix and the result of F1 score, this model is not efficient to predict whether or not a customer will buy the insurance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes model\n",
    "\n",
    "Let's train a Naive Bayes model with our training data. We need to import the Naive Model from the sklearn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "naivemodel = GaussianNB()\n",
    "\n",
    "naivemodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`naivemodel.fit()` trained the Naive Bayes model. The model is now ready to make prediction for the unknown label by using only the features from the test data (`X_test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naivemodel_prediction = naivemodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can call one `naivemodel_prediction`to see the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naivemodel_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the `ConfusionMatrix()` function, we can see how the model performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrix(y_test, naivemodel_prediction, label= [\"not-purchaed\", \"purchased\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of the Naive model evaluation performance\n",
    "\n",
    "There are 48 True Negatives (TN): predicting that the customer will not buy the insurance and truly the customer did not buy the insurance.\n",
    "\n",
    "There are 20 True Positives (TP): predicting that the customer will buy the insurance and truly the customer did buy the insurance.\n",
    "\n",
    "There are 7 False Negatives (FN): predicting that the customer will not buy the insurance and the customer actually bought the insurance.\n",
    "\n",
    "There are 5 False Positives (FN): predicting that the customer will buy the insurance and the customer did not buy the insurance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to check the **accuracy** and **F1** score of them model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can check the accuracy by using:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test, naivemodel_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the model is $85\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can check the F1 score by using:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(y_test, naivemodel_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F1 score of the model is $76.9\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this model seems good in predicting whether a patient will buy insurance or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model\n",
    "\n",
    "Let's train a Random Forest model with our training data. We need to import the Random Forest model from the sklearn module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randomforestmodel = RandomForestClassifier()\n",
    "\n",
    "randomforestmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`randomforestmodel.fit()` trained the Random Forest model on the training data. The model is now ready to make prediction for the unknown label by using only the features from the test data (`X_test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforestmodel_prediction = randomforestmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can call one `randomforestmodel_prediction` to see the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforestmodel_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the `ConfusionMatrix()` function, we can see how the model performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrix(y_test, randomforestmodel_prediction, label= [\"not-purchaed\", \"purchased\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of the Random Forest model evaluation performance\n",
    "\n",
    "There are 44 True Negatives (TN): predicting that the customer will not buy the insurance and truly the customer did not buy the insurance.\n",
    "\n",
    "There are 23 True Positives (TP): predicting that the customer will buy the insurance and truly the customer did buy the insurance.\n",
    "\n",
    "There are 4 False Negatives (FN): predicting that the customer will not buy the insurance and the customer actually bought the insurance.\n",
    "\n",
    "There are 9 False Positives (FN): predicting that the customer will buy the insurance and the customer did not buy the insurance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to check the **accuracy** and **F1** score of them model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can check the accuracy by using:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test, randomforestmodel_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the model is $83.75\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can check the F1 score by using:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(y_test, randomforestmodel_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F1 score of the model is $77.97\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this model seems good in predicting whether a patient will buy insurance or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extreme Gradient Boost (XGBoost) Model\n",
    "\n",
    "Let's train an XGBoost model with our training data. We need to import the XGBoost model from the sklearn module but before we do that, we need to install the module because it is not available in the sklearn.\n",
    "\n",
    "## How to install XGBoost\n",
    "\n",
    "Go to your termina and type `pip install xgboost`\n",
    "\n",
    "`pip install xgboost`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../Images/install_XGboost.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After installation, you can now import it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgboostmodel = XGBClassifier(use_label_encoder=False)\n",
    "\n",
    "xgbboostmodel = xgboostmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`xgboostmodel.fit()` trained the XGBoost model on the training data. The model is now ready to make prediction for the unknown label by using only the features from the test data (`X_test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbboostmodel_prediction = xgboostmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can call on `xgbboostmodel_prediction` to see the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbboostmodel_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the `ConfusionMatrix()` function, we can see how the model performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrix(y_test, xgbboostmodel_prediction, label= [\"not-purchaed\", \"purchased\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of the XGBoost model evaluation performance\n",
    "\n",
    "There are 45 True Negatives (TN): predicting that the customer will not buy the insurance and truly the customer did not buy the insurance.\n",
    "\n",
    "There are 21 True Positives (TP): predicting that the customer will buy the insurance and truly the customer did buy the insurance.\n",
    "\n",
    "There are 6 False Negatives (FN): predicting that the customer will not buy the insurance and the customer actually bought the insurance.\n",
    "\n",
    "There are 8 False Positives (FN): predicting that the customer will buy the insurance and the customer did not buy the insurance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to check the **accuracy** and **F1** score of them model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can check the accuracy by using:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test, xgbboostmodel_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the model is $82.5\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can check the F1 score by using:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(y_test, xgbboostmodel_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F1 score of the model is $75\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this model seems good in predicting whether a patient will buy insurance or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)\n",
    "\n",
    "Let's train a Support Vector Machine model with our training data. We need to import the Support Vector Machine model from the sklearn module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "SVMmodel = SVC()\n",
    "\n",
    "SVMmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SVMmodel.fit()` trained the Support Vector Machine on the training data. The model is now ready to make prediction for the unknown label by using only the features from the test data (`X_test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMmodel_prediction = SVMmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can call on `SVMmodel_prediction` to see what has been predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMmodel_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the `ConfusionMatrix()` function, we can see how the model performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrix(y_test, SVMmodel_prediction, label= [\"not-purchaed\", \"purchased\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of the Random Forest model evaluation performance\n",
    "\n",
    "There are 50 True Negatives (TN): predicting that the customer will not buy the insurance and truly the customer did not buy the insurance.\n",
    "\n",
    "There are 14 True Positives (TP): predicting that the customer will buy the insurance and truly the customer did buy the insurance.\n",
    "\n",
    "There are 13 False Negatives (FN): predicting that the customer will not buy the insurance and the customer actually bought the insurance.\n",
    "\n",
    "There are 3 False Positives (FN): predicting that the customer will buy the insurance and the customer did not buy the insurance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to check the **accuracy** and **F1** score of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can check the accuracy by using:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test, SVMmodel_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the model is $80\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can check the F1 score by using:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(y_test, SVMmodel_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F1 score of the model is $63.6\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this model seems good in predicting whether a patient will buy insurance or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Models Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+-----------------------+----------------------+-----------------------+\n",
    "| Model (s)             | Accuracy             | F1-score              |\n",
    "+=======================+======================+=======================+\n",
    "| Logistic regression   | 66.25                | 0                     |\n",
    "+-----------------------+----------------------+-----------------------+\n",
    "| Naive Bayes           | 85                   | 76.92                 |\n",
    "+-----------------------+----------------------+-----------------------+\n",
    "| Random Forest         | 83.75                | 77.97                 |\n",
    "+-----------------------+----------------------+-----------------------+\n",
    "| XGBoost               | 82.5                 | 75                    |\n",
    "+-----------------------+----------------------+-----------------------+\n",
    "| SVM                   | 80                   | 63.63                 |\n",
    "+-----------------------+----------------------+-----------------------+\n",
    "\n",
    "![](../Images/metrics.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having train all the five (5) models, we can see that the best model that can accurately predict whether a customer will buy the insurance or not is the Random Forest Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Scikit-learn Module\n",
    "\n",
    "Use the following models to predict whether a customer will buy insurance or not. Your teacher has also included how to import those models for you.\n",
    "\n",
    "* **K Nearest Neighbor**: `from sklearn.neighbors import KNeighborsClassifier`\n",
    "\n",
    "* **Decision Trees Classifier**: `from sklearn.tree import DecisionTreeClassifier`\n",
    "\n",
    "* **Gradient Boost Classifier**: `from sklearn.ensemble import GradientBoostingClassifier`\n",
    "\n",
    "Which of the three (3) model is the best in term of the F1 score?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
